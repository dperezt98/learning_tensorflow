{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ejercicio 5 - Redes neuronales recurrentes.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOTAoH0KlHuDu2YDnZi2VkP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Redes neuronales recurrentes"],"metadata":{"id":"tFskzxwqnl7o"}},{"cell_type":"markdown","source":["## Caso de estudio: Generación de texto"],"metadata":{"id":"60XD26i5nrEX"}},{"cell_type":"markdown","source":["### Datos de tipo texto y redes neuronales\n","Recordemos que todas las entradas en una red neuronal\n","deben ser tensores de datos numéricos. Cualquier dato que se necesite\n","procesar. Primero debe ser convertido en un tensor\n","numérico, un paso llamado \"vectorización\" de datos.\n","\n","Para ello usaremos *Word Embedding*, crea vectores de tamaños reducidos pero que preservan las relaciones semánticas. Un detalle muy importante.\n","\n","### *Character-Level Language Models*\n","Consiste en darle a la RNN una\n","palabra y se le pide que modele la distribución de probabilidad del siguiente\n","carácter que le correspondería a la secuencia de caracteres anteriores. Con\n","este modelo, si lo llamamos repetitivamente, podremos generar texto carácter\n","a carácter.\n","\n","Para usar el modelo, introducimos un carácter en la RNN y obtenemos una\n","distribución sobre qué carácter probablemente será el siguiente. Tomamos\n","una muestra de esta distribución y la retroalimentamos para obtener el\n","siguiente carácter. ¡Repetimos este proceso y estamos generando texto!"],"metadata":{"id":"W8ksuBr0n0Bk"}},{"cell_type":"markdown","source":["## Descarga y preprocesado de datos\n","El primer paso en este ejemplo será el descargar y preparar el conjunto de\n","datos con el que entrenaremos nuestra red neuronal:"],"metadata":{"id":"HsnnG1YyoxFt"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b14Vzesy_sTP","executionInfo":{"status":"ok","timestamp":1646385838610,"user_tz":-60,"elapsed":5345,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"64f1dab0-ea1f-4482-adc1-a61191599181"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/jorditorresBCN/Deep-Learning-Introduccion-practica-con-Keras/master/DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt\n","204800/203286 [==============================] - 0s 0us/step\n","212992/203286 [===============================] - 0s 0us/step\n","Longitud del texto: 203251 carácteres\n","El texto está compuesto de estos 92 carácteres:\n","['\\n', '\\r', ' ', '!', '\"', '#', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'ÿ', 'Š', '‡', '…']\n"]}],"source":["import tensorflow as tf\n","path_to_fileDL = tf.keras.utils.get_file('DL-Introduccion-practica-con-Keras-1a.txt',\n","'https://raw.githubusercontent.com/jorditorresBCN/Deep-Learning-Introduccion-practica-con-Keras/master/DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt')\n","\n","text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n","print('Longitud del texto: {} carácteres'.format(len(text)))\n","vocab = sorted(set(text))\n","\n","print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n","print (vocab)"]},{"cell_type":"markdown","source":["Como estas tratando el caso de estudio a nivel de carácter, podríamos considerar que aquí el corpus (recopilatorio) son los caracteres, por tanto un corpus muy pequeño. \n","\n","Recordemos que las redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica. Para ello crearemos dos \"tablas de traducción\": una de caracteres a números y otra de números a caracteres:"],"metadata":{"id":"H-cfrkCxqz55"}},{"cell_type":"code","source":["import numpy as np\n","\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","# Ahora tenemos una representacion de un numero para cada caracter\n","for char,_ in zip(char2idx, range(len(vocab))):\n","  print(' {:4s}: {:3d},'.format(repr(char), char2idx[char]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5XWBZ0XTrZLX","executionInfo":{"status":"ok","timestamp":1646385838611,"user_tz":-60,"elapsed":24,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"84ae68da-1747-4e86-d147-130a0afd0f6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" '\\n':   0,\n"," '\\r':   1,\n"," ' ' :   2,\n"," '!' :   3,\n"," '\"' :   4,\n"," '#' :   5,\n"," '%' :   6,\n"," \"'\" :   7,\n"," '(' :   8,\n"," ')' :   9,\n"," '*' :  10,\n"," '+' :  11,\n"," ',' :  12,\n"," '-' :  13,\n"," '.' :  14,\n"," '/' :  15,\n"," '0' :  16,\n"," '1' :  17,\n"," '2' :  18,\n"," '3' :  19,\n"," '4' :  20,\n"," '5' :  21,\n"," '6' :  22,\n"," '7' :  23,\n"," '8' :  24,\n"," '9' :  25,\n"," ':' :  26,\n"," ';' :  27,\n"," '<' :  28,\n"," '=' :  29,\n"," '>' :  30,\n"," '?' :  31,\n"," '@' :  32,\n"," 'A' :  33,\n"," 'B' :  34,\n"," 'C' :  35,\n"," 'D' :  36,\n"," 'E' :  37,\n"," 'F' :  38,\n"," 'G' :  39,\n"," 'H' :  40,\n"," 'I' :  41,\n"," 'J' :  42,\n"," 'K' :  43,\n"," 'L' :  44,\n"," 'M' :  45,\n"," 'N' :  46,\n"," 'O' :  47,\n"," 'P' :  48,\n"," 'Q' :  49,\n"," 'R' :  50,\n"," 'S' :  51,\n"," 'T' :  52,\n"," 'U' :  53,\n"," 'V' :  54,\n"," 'W' :  55,\n"," 'X' :  56,\n"," 'Y' :  57,\n"," '[' :  58,\n"," ']' :  59,\n"," '_' :  60,\n"," 'a' :  61,\n"," 'b' :  62,\n"," 'c' :  63,\n"," 'd' :  64,\n"," 'e' :  65,\n"," 'f' :  66,\n"," 'g' :  67,\n"," 'h' :  68,\n"," 'i' :  69,\n"," 'j' :  70,\n"," 'k' :  71,\n"," 'l' :  72,\n"," 'm' :  73,\n"," 'n' :  74,\n"," 'o' :  75,\n"," 'p' :  76,\n"," 'q' :  77,\n"," 'r' :  78,\n"," 's' :  79,\n"," 't' :  80,\n"," 'u' :  81,\n"," 'v' :  82,\n"," 'w' :  83,\n"," 'x' :  84,\n"," 'y' :  85,\n"," 'z' :  86,\n"," '\\xad':  87,\n"," 'ÿ' :  88,\n"," 'Š' :  89,\n"," '‡' :  90,\n"," '…' :  91,\n"]}]},{"cell_type":"markdown","source":["Ahora tenemos una representación de entero (integer) para cada carácter. Y ahora esta función inversa a la anterior podemos pasar el texto a enteros:"],"metadata":{"id":"rG5_Z2Tqs0ZP"}},{"cell_type":"code","source":["text_as_int = np.array([char2idx[c] for c in text])\n","\n","print ('texto: {}'.format(repr(text[:50])))\n","print ('{}'.format(repr(text_as_int[:50])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HlsFJDVys9JQ","executionInfo":{"status":"ok","timestamp":1646385839137,"user_tz":-60,"elapsed":542,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"e8d2ff38-03df-4083-e551-9ae9df3d806e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["texto: 'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fun'\n","array([48, 78, 75, 72, 75, 67, 75,  1,  0, 37, 74,  2, 17, 25, 21, 19, 12,\n","        2, 41, 79, 61, 61, 63,  2, 33, 79, 69, 73, 75, 82,  2, 76, 81, 62,\n","       72, 69, 63, 75,  2, 51, 65, 67, 81, 74, 64, 61,  2, 38, 81, 74])\n"]}]},{"cell_type":"markdown","source":["## Preparación de los datos para ser usados por la RNN\n","Para entrenar el modelo prepararemos unas secuencias de caracteres como\n","entradas y salida de un tamaño determinado. En nuestro ejemplo hemos\n","definido el tamaño de 100 caracteres con la variable seq_length.\n","\n","Empezamos dividiendo el texto que tenemos en secuencias de\n","seq_length+1 de caracteres con las cuales luego contruiremos los datos de\n","entrenamiento compuestos por las entradas de seq_length caracteres y las\n","salidas correspondientes que contienen la misma longitud de texto, excepto\n","que se desplaza un carácter a la derecha.\n","\n","Usaremos la función tf.data.Dataset.from_tensor_slices, que\n","crea un conjunto de datos con el contenido del tensor text_as_int que\n","contiene el texto, al que podremos aplicar el método batch( )para dividir\n","este conjunto de datos en secuencias de seq_length+1 de índice de caracteres:"],"metadata":{"id":"ss3_gCgXtHaZ"}},{"cell_type":"code","source":["char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","seq_length = 100\n","sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"],"metadata":{"id":"FE5B9Oc7uMFC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos comprobar que *sequences* contiene el texto dividido en paquetes\n","de 101 caracteres como esperamos (por ejemplo mostremos las 10 primeras\n","secuencias):"],"metadata":{"id":"xpYiirqVuTTM"}},{"cell_type":"code","source":["for item in sequences.take(10):\n","  print(repr(''.join(idx2char[item.numpy()])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78seO8t2uZkC","executionInfo":{"status":"ok","timestamp":1646385842573,"user_tz":-60,"elapsed":12,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"ef1c03bd-9a5d-475a-b6c7-423fcbdd6c8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n","'(o el decimotercero segun otras fuentes, este es un tema de debate). En Segunda Fundacion aparece por'\n","' primera vez Arkady Darell, uno de los principales personajes de la parte final de la saga. En su pri'\n","'mera escena, Arkady, que tiene 14 anos, esta haciendo sus tareas escolares. En concreto, una redaccio'\n","'n que lleva por titulo ?El Futuro del Plan Sheldon?. Para hacer la redaccion, Arkady esta utilizando '\n","'un ?transcriptor?,un dispositivo que convierte su voz en palabras escritas. Este tipo de dispositivo,'\n","' que para Isaac Asimov era ciencia ficcion en 1953, lo tenemos al alcance de la mano en la mayoria de'\n","' nuestros smartphones, y el Deep Learning es uno de los responsables de que ya tengamos este tipo de '\n","'aplicaciones, siendo la tecnologia otro de ellos.En la actualidad disponemos de GPUs (Graphics Proces'\n","'sor Units), que solo cuestan alrededor de 100 euros, que estarian en la lista del Top500 hace unos po'\n"]}]},{"cell_type":"markdown","source":["De esta secuencia se obtiene el conjunto de datos de training que contenga\n","tanto los datos de entrada (desde la posición 0 a la 99) como los datos de\n","salida (desde la posición 1 a la 100). Para ello se crea una función que realiza\n","esta tarea y se aplica a todas las secuencias usando el método *map( )* de la\n","siguiente forma:"],"metadata":{"id":"suUDK-fXulWL"}},{"cell_type":"code","source":["def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text = chunk[1:]\n","  return input_text, target_text\n","  \n","dataset = sequences.map(split_input_target)"],"metadata":{"id":"TFo-W7LVup5Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este punto, dataset contiene un conjunto de parejas de secuencias de\n","texto (con la representación numérica de los caracteres), donde el primer componente de la pareja contiene un paquete con una secuencia de 100\n","caracteres del texto original y la segunda su correspondiente salida, también\n","de 100 caracteres. Podemos comprobarlo visualizándolo por pantalla (por\n","ejemplo mostrando la primera pareja):"],"metadata":{"id":"p_KUqUjHu2VB"}},{"cell_type":"code","source":["for input_example, target_example in dataset.take(1):\n","  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARV7qDcXu9wc","executionInfo":{"status":"ok","timestamp":1646385843108,"user_tz":-60,"elapsed":22,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"a41aecc7-8117-4b93-dccd-f538a9e6d855"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input data:  'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion'\n","Target data: 'rologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n"]}]},{"cell_type":"markdown","source":["En este punto del código disponemos de los datos de entrenamiento en el\n","tensor dataset en forma de parejas de secuencias de 100 integers de 64 bits\n","que representan un carácter del vocabulario:"],"metadata":{"id":"h6Ua7-t6vKdB"}},{"cell_type":"code","source":["print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMCTibG3vLqq","executionInfo":{"status":"ok","timestamp":1646385843109,"user_tz":-60,"elapsed":20,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"fdecb6bc-95e3-4f2e-81cb-cd80d40dd0a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"markdown","source":["En realidad los datos ya están preprocesados en el formato que se requiere\n","para ser usados en el entreno de la red neuronal, pero recordemos que en\n","redes neuronales los datos se agrupan en batches antes de pasarlos al modelo.\n","En nuestro caso hemos decidido un tamaño de batch de 64, que nos facilita la\n","explicación, este es un\n","hiperparámetro importante de ajustar correctamente teniendo en cuenta\n","diferentes factores, como el tamaño de la memoria disponible, por poner un\n","ejemplo. En este código, para crear los batches de parejas de secuencias hemos\n","considerado usar tf.data que además nos permite barajar84 las secuencias\n","previamente:"],"metadata":{"id":"_LNYkaw3vX9n"}},{"cell_type":"code","source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print (dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eM4PP5HZvexU","executionInfo":{"status":"ok","timestamp":1646388255701,"user_tz":-60,"elapsed":990,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"25b67a6b-af2c-4eb0-cab3-d181fcbc59d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<BatchDataset element_spec=(TensorSpec(shape=(64, 64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 64, 100), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"markdown","source":["Recapitulando, ahora en el tensor dataset disponemos de los datos de\n","entrenamiento ya listos para ser usados para entrenar el modelo: batches\n","compuestos de 64 parejas de secuencias de 100 integers de 64 bits que\n","representan el carácter correspondiente en el vocabulario."],"metadata":{"id":"gqq99XXZvljT"}},{"cell_type":"markdown","source":["## Construcción del modelo RNN\n","Para construir el modelo usaremos tf.keras.Sequential que ya\n","conocemos. Usaremos una versión mínima de RNN para facilitar la\n","explicación, que contenga solo una capa LSTM. En concreto definimos una\n","red de solo 3 capas:"],"metadata":{"id":"j0nv1bEHvqaZ"}},{"cell_type":"code","source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = Sequential()\n","  model.add(Embedding(input_dim=vocab_size, \n","                      output_dim=embedding_dim, \n","                      batch_input_shape=[batch_size, None]))\n","  model.add(LSTM(rnn_units,\n","                 return_sequences=True,\n","                 stateful=True,\n","                 recurrent_initializer='glorot_uniform'))\n","  model.add(Dense(vocab_size))\n","  return model\n","\n","\n","\n","vocab_size = len(vocab)\n","embedding_dim = 256\n","rnn_units = 1024"],"metadata":{"id":"UUZzgfDhvn3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = build_model(\n","  vocab_size = vocab_size,\n","  embedding_dim=embedding_dim,\n","  rnn_units=rnn_units,\n","  batch_size=BATCH_SIZE)"],"metadata":{"id":"R4Mkk9JQwiHC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La primera capa es de tipo Word Embedding como las que antes hemos\n","presentado muy brevemente que mapea cada carácter de entrada en un\n","vector Embedding. Esta capa tf.keras.layers. Embedding permite\n","especificar varios argumentos que se pueden consultar en todo detalle en el\n","manual de TensorFlow.\n","\n","En nuestro caso el primero que especificamos es el tamaño del vocabulario,\n","indicado con el argumento vocab_size, que indica cuantos vectores\n","Embedding tendrá la capa. A continuación indicamos las dimensiones de estos\n","vectores Embedding mediante el argumento embedding_dim, que en nuestro\n","caso hemos decidido que sea 256. Finalmente se indica el tamaño del batch\n","que usaremos para entrenar, en nuestro caso 64.\n","\n","La segunda capa es de tipo LSTM introducida anteriormente en este\n","capítulo. Esta capa tf.keras.layers.LSTM tiene varios argumentos\n","posibles que se pueden consultar en el manual de TensorFlow, aquí solo\n","usaremos algunos y dejamos los valores por defecto del resto. Quizás el más\n","importante es el número de neuronas recurrentes que se indica con el\n","argumento units y que en nuestro caso hemos decidido que sea 1024\n","neuronas.\n","\n","Con return_sequence se indica que queremos predecir el carácter siguiente a todos los caracteres de entrada, no solo el siguiente al último\n","carácter.\n","\n","El argumento stateful indica, explicado de manera simple, el uso de las\n","capacidades de memoria de la red entre batches. Si este argumento está\n","instanciado a false se indica que a cada nuevo batch se inicializan las memory\n","cells comentadas anteriormente, mientras que si está a true se está indicando\n","para cada batch se mantendrán las actualizaciones hechas durante la\n","ejecución del bach anterior.\n","\n","El último argumento que usamos es recurrent_kernel, donde indicamos\n","cómo se deben inicializar los pesos de las matrices internas de la red. En este\n","caso usamos la distribución uniforme glorot_uniform, habitual en estos\n","casos.\n","\n","Finalmente la última capa es de tipo Dense, ya explicada previamente en\n","este libro. Aquí es importante el argumento units que nos dice cuantas\n","neuronas tendrá la capa y que nos marcará la dimensión de la salida. En\n","nuestro caso será igual al tamaño de nuestro vocabulario (vocab_size).\n","\n","Como siempre, es interesante usar el método summary() para visualizar la\n","estructura del modelo:"],"metadata":{"id":"wb0Sob0LwxRi"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hi3tCglBxqBX","executionInfo":{"status":"ok","timestamp":1646385844437,"user_tz":-60,"elapsed":16,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"b645d4b1-8b11-4b05-eb55-f2aed7fb635b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (64, None, 256)           23552     \n","                                                                 \n"," lstm (LSTM)                 (64, None, 1024)          5246976   \n","                                                                 \n"," dense (Dense)               (64, None, 92)            94300     \n","                                                                 \n","=================================================================\n","Total params: 5,364,828\n","Trainable params: 5,364,828\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Podemos comprobar que la capa LSTM consta de muchos parámetros (más\n","de 5 millones) como era de esperar. Intentemos analizar un poco más esta\n","red neuronal. Para cada carácter de entrada (transformado a su equivalente\n","numérico), el modelo busca su vector de Embedding correspondiente y luego\n","ejecuta la capa LSTM con este vector Embedding como entrada. A la salida\n","de la LSTM aplica la capa Dense para decidir cual es el siguiente carácter.\n","\n","Inspeccionemos las dimensiones de los tensores para poder comprender más\n","a fondo el modelo. Fijemonos en el primer batch del conjunto de datos de\n","entrenamiento y observemos su forma:"],"metadata":{"id":"SDqWnYPlx7uH"}},{"cell_type":"code","source":["for input_example_batch, target_example_batch in dataset.take(1):\n","  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n","  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dCCUixhHx8gV","executionInfo":{"status":"ok","timestamp":1646385845435,"user_tz":-60,"elapsed":1005,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"0843e402-1089-4ed3-dd40-69bd63923aff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: (64, 100) # (batch_size, sequence_length)\n","Target: (64, 100) # (batch_size, sequence_length)\n"]}]},{"cell_type":"markdown","source":["Vemos que en esta red la secuencia de entrada son batch de 100 caracteres,\n","pero el modelo una vez entrenado puede ser ejecutado con cualquier tamaño\n","de cadena de entrada. Este es un detalle al que luego volveremos."],"metadata":{"id":"mNW98JotyZwD"}},{"cell_type":"code","source":["for input_example_batch, target_example_batch in dataset.take(1):  \n","    example_batch_predictions = model(input_example_batch)\n","    print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LO5L6DwByfTz","executionInfo":{"status":"ok","timestamp":1646385850615,"user_tz":-60,"elapsed":5186,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"3a996fb3-d637-4955-8413-8045657395b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction:  (64, 100, 92) # (batch_size, sequence_length, vocab_size)\n"]}]},{"cell_type":"markdown","source":["la capa densa de\n","esta red neuronal no tiene una función de activación softmax como la capa\n","densa que se presentó en ejercicios anteriores. De aquí que retorne el vector con un\n","indicador de “evidencia” para cada carácter.\n","\n","El siguiente paso es elegir uno de los caracteres. Sin entrar en detalle, no se eligirá el carácter más “probable” (mediante argmax) como se hizo en ejercicios anteriores puesto que el modelo pueda entrar en un bucle. Lo que se hará es\n","obtener una muestra de la distribución de salida. Pruébelo para el primer\n","ejemplo en el batch:"],"metadata":{"id":"mt1b7XI9yoIQ"}},{"cell_type":"code","source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()\n","print (sampled_indices_characters)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGt7m0DLy50b","executionInfo":{"status":"ok","timestamp":1646385850616,"user_tz":-60,"elapsed":25,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"a3a3df47-21f7-4f1b-bf36-452050fe95e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[48 86 46 17 47 35 87  5 54 74 11 39 76 41 33  7 70 42 62 41 15 66 18 81\n"," 83 43 70 60 17 40 81 48 12 26 18 87 46 82 21 14 35  4 41 52 48  6 89 70\n"," 66 19  0 44 41 70  4 51 49 25 54 63 75 37  0 57 22 14 88 43 14 62 46 50\n"," 59 40 22 48  0 83  9 21 60  5 84 66 79  2 62 91 43  9 85 61 21 69 69  6\n"," 72 11  5 22]\n"]}]},{"cell_type":"markdown","source":["Con tf.random.categorical se obtiene una muestra de una distribución\n","categórica y con squeeze se elimina la dimensiones del tensor de tamaño 1.\n","De esta manera en cada instante de tiempo se obtiene una predicción del\n","índice del siguiente carácter."],"metadata":{"id":"TG0pJksYzJ03"}},{"cell_type":"markdown","source":["### Entrenamiento del modelo\n","En este punto, el problema puede tratarse como un problema de clasificación estándar para el que debemos definir la función de *Loss* y el optimizador.\n","\n","Para\n","la\n","función\n","de\n","Loss\n","usaremos\n","la\n","función\n","estándar\n","tf.keras.losses.sparse_categorical_crossentropy dado que\n","estamos considerando datos categóricos. Dado que el retorno hemos visto\n","que se trata de unos valores de verisimilitud (no de probabilidades como si\n","hubiéramos ya aplicado softmax) se instanciará el argumento from_logits a\n","True\n","\n"],"metadata":{"id":"1H_2xtWfNzlp"}},{"cell_type":"code","source":["def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits,\n","                                                        from_logits=True)"],"metadata":{"id":"ll4BRTebzMaa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En cuanto al optimizador usaremos tf.keras.optimizers.Adam con\n","los argumentos por defecto del optimizador Adam.\n","\n","Con esta función de loss definida y usando el optimizador Adam con sus\n","argumentos por defecto, ya podemos llamar al método compile () de la\n","siguiente manera:"],"metadata":{"id":"sVFPOg43OUtH"}},{"cell_type":"code","source":["model.compile(optimizer='adam', loss=loss)"],"metadata":{"id":"RD9MPyUNOWJe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este ejemplo aprovecharemos para usar los Checkpoints87, una técnica de\n","tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La\n","idea es guardar una instantánea del estado del sistema periódicamente para\n","recuperar desde ese punto la ejecución en caso de fallo del sistema. En\n","nuestro caso, cuando entrenamos modelos Deep Learning, el Checkpoint lo\n","forman básicamente los pesos del modelo. Estos Checkpoint se pueden usar\n","también para hacer predicciones tal cual como haremos en este ejemplo.\n","La librería de Keras proporciona Checkpoints a través de la API Callbacks.\n","Concretamente\n","usaremos\n","tf.keras.callbacks.ModelCheckpoint88\n","para especificar cómo salvar los Checkpoints a cada epoch durante el\n","entrenamiento, a través de un argumento en el método fit() del modelo.\n","\n","En el código debemos especificar el directorio en el que se guardarán los\n","Checkpoints que salvaremos y el nombre del fichero (que le añadiremos el número de epoch para nuestra comodidad):"],"metadata":{"id":"q21GHr1lOlmL"}},{"cell_type":"code","source":["import os\n","\n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)\n"],"metadata":{"id":"_kMRTSTVOwaJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora ya está todo preparado para empezar a entrenar la red con el método\n","fit():"],"metadata":{"id":"KYajEGsAPOod"}},{"cell_type":"code","source":["EPOCHS=50\n","history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ND-08IedPQOS","executionInfo":{"status":"ok","timestamp":1646386248691,"user_tz":-60,"elapsed":398091,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"5d5c9a28-04af-4640-fd4c-7221b1b17a81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","31/31 [==============================] - 8s 175ms/step - loss: 3.2353\n","Epoch 2/50\n","31/31 [==============================] - 6s 173ms/step - loss: 2.7716\n","Epoch 3/50\n","31/31 [==============================] - 6s 175ms/step - loss: 2.4370\n","Epoch 4/50\n","31/31 [==============================] - 6s 175ms/step - loss: 2.2158\n","Epoch 5/50\n","31/31 [==============================] - 6s 173ms/step - loss: 2.0992\n","Epoch 6/50\n","31/31 [==============================] - 6s 175ms/step - loss: 1.9865\n","Epoch 7/50\n","31/31 [==============================] - 6s 175ms/step - loss: 1.8708\n","Epoch 8/50\n","31/31 [==============================] - 6s 174ms/step - loss: 1.7563\n","Epoch 9/50\n","31/31 [==============================] - 6s 173ms/step - loss: 1.6489\n","Epoch 10/50\n","31/31 [==============================] - 6s 174ms/step - loss: 1.5503\n","Epoch 11/50\n","31/31 [==============================] - 6s 175ms/step - loss: 1.4596\n","Epoch 12/50\n","31/31 [==============================] - 6s 174ms/step - loss: 1.3845\n","Epoch 13/50\n","31/31 [==============================] - 6s 174ms/step - loss: 1.3128\n","Epoch 14/50\n","31/31 [==============================] - 6s 175ms/step - loss: 1.2569\n","Epoch 15/50\n","31/31 [==============================] - 6s 175ms/step - loss: 1.2012\n","Epoch 16/50\n","31/31 [==============================] - 6s 182ms/step - loss: 1.1532\n","Epoch 17/50\n","31/31 [==============================] - 6s 180ms/step - loss: 1.1095\n","Epoch 18/50\n","31/31 [==============================] - 6s 175ms/step - loss: 1.0612\n","Epoch 19/50\n","31/31 [==============================] - 6s 174ms/step - loss: 1.0202\n","Epoch 20/50\n","31/31 [==============================] - 6s 173ms/step - loss: 0.9794\n","Epoch 21/50\n","31/31 [==============================] - 6s 171ms/step - loss: 0.9463\n","Epoch 22/50\n","31/31 [==============================] - 6s 177ms/step - loss: 0.9090\n","Epoch 23/50\n","31/31 [==============================] - 6s 180ms/step - loss: 0.8726\n","Epoch 24/50\n","31/31 [==============================] - 6s 176ms/step - loss: 0.8343\n","Epoch 25/50\n","31/31 [==============================] - 6s 182ms/step - loss: 0.7993\n","Epoch 26/50\n","31/31 [==============================] - 6s 176ms/step - loss: 0.7617\n","Epoch 27/50\n","31/31 [==============================] - 6s 179ms/step - loss: 0.7266\n","Epoch 28/50\n","31/31 [==============================] - 6s 185ms/step - loss: 0.6942\n","Epoch 29/50\n","31/31 [==============================] - 6s 177ms/step - loss: 0.6584\n","Epoch 30/50\n","31/31 [==============================] - 6s 178ms/step - loss: 0.6268\n","Epoch 31/50\n","31/31 [==============================] - 6s 182ms/step - loss: 0.5925\n","Epoch 32/50\n","31/31 [==============================] - 6s 180ms/step - loss: 0.5589\n","Epoch 33/50\n","31/31 [==============================] - 6s 178ms/step - loss: 0.5288\n","Epoch 34/50\n","31/31 [==============================] - 6s 179ms/step - loss: 0.5005\n","Epoch 35/50\n","31/31 [==============================] - 6s 179ms/step - loss: 0.4722\n","Epoch 36/50\n","31/31 [==============================] - 6s 176ms/step - loss: 0.4509\n","Epoch 37/50\n","31/31 [==============================] - 6s 185ms/step - loss: 0.4236\n","Epoch 38/50\n","31/31 [==============================] - 6s 180ms/step - loss: 0.4022\n","Epoch 39/50\n","31/31 [==============================] - 6s 182ms/step - loss: 0.3805\n","Epoch 40/50\n","31/31 [==============================] - 6s 176ms/step - loss: 0.3649\n","Epoch 41/50\n","31/31 [==============================] - 6s 179ms/step - loss: 0.3474\n","Epoch 42/50\n","31/31 [==============================] - 6s 186ms/step - loss: 0.3345\n","Epoch 43/50\n","31/31 [==============================] - 6s 175ms/step - loss: 0.3236\n","Epoch 44/50\n","31/31 [==============================] - 6s 179ms/step - loss: 0.3105\n","Epoch 45/50\n","31/31 [==============================] - 6s 176ms/step - loss: 0.2991\n","Epoch 46/50\n","31/31 [==============================] - 6s 179ms/step - loss: 0.2877\n","Epoch 47/50\n","31/31 [==============================] - 6s 183ms/step - loss: 0.2828\n","Epoch 48/50\n","31/31 [==============================] - 6s 176ms/step - loss: 0.2746\n","Epoch 49/50\n","31/31 [==============================] - 6s 181ms/step - loss: 0.2685\n","Epoch 50/50\n","31/31 [==============================] - 6s 178ms/step - loss: 0.2616\n"]}]},{"cell_type":"markdown","source":["## Generación de texto usando el modelo RNN\n","\n","Ahora que tenemos ya entrenado el modelo pasemos a usarlo para generar\n","texto. Para mantener este paso de predicción simple, vamos a usar un tamaño\n","de batch de 1. Debido a la forma en que se pasa el estado de la RNN de un\n","instante de tiempo al siguiente, el modelo solo acepta un tamaño de batch fijo\n","una vez construido. Por ello, para poder ejecutar el modelo con un tamaño\n","de batch diferente, necesitamos reconstruir manualmente el modelo con el\n","método build( ) del modelo y restaurar sus pesos desde el Checkpoints\n","(cogemos el ultimo con tf.train.latest_checkpoint ()):"],"metadata":{"id":"8wwMgJEvPYkg"}},{"cell_type":"code","source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","model.build(tf.TensorShape([1, None]))"],"metadata":{"id":"6NVAg4IHQAkB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora que tenemos el modelo entrenado y preparado para usar,\n","generaremos texto a partir de una palabra de partida con el siguiente código:"],"metadata":{"id":"a12UbSjfQNcA"}},{"cell_type":"code","source":["def generate_text(model, start_string):\n","  num_generate = 500\n","  input_eval = [char2idx[s] for s in start_string]\n","\n","  input_eval = tf.expand_dims(input_eval, 0)\n","  text_generated = []\n","\n","  temperature = 0.5\n","\n","  model.reset_states()\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","\n","    predictions = tf.squeeze(predictions, 0)\n","    predictions = predictions / temperature\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","    input_eval = tf.expand_dims([predicted_id], 0)\n","\n","    text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"],"metadata":{"id":"D9LFA_V8QOZd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El código empieza con inicializaciones como: definir el número de caracteres\n","a predecir con la variable num_generate, convertir la palabra inicial\n","(start_string) a su correspondiente representación numérica y preparan\n","lo tensores necesarios. Después se usa una variable temperature para decidir cómo de conservador en sus\n","predicciones queremos que se comporte nuestro modelo. En nuestro ejemplo\n","la hemos inicializado a 0.5. Con “temperaturas altas” (hasta 1) se permitirá más creatividad al modelo\n","para generar texto pero a costa de más errores (por ejemplo, errores\n","ortográficos, etc.). Mientras que con “temperaturas bajas” habrá menos\n","errores pero el modelo mostrará poca creatividad.\n","\n","Luego, se usa una distribución categórica para calcular el índice del carácter\n","predicho(predictions y predicted_id).\n","\n","Este carácter acabado de predecir se usa como nuestra próxima entrada al\n","modelo, retroalimentando el modelo para que ahora tenga más contexto (en\n","lugar de una sola letra). Después de predecir la siguiente letra, se\n","retroalimenta nuevamente, y así sucesivamente de manera que es cómo\n","aprende a medida que se obtiene más contexto de los carácteres predichos\n","previamente (input_val y text_generated.append())"],"metadata":{"id":"JF5FSiZLVQZ5"}},{"cell_type":"markdown","source":["Empecemos con una palabra que no conoce el corpus, por ejemplo\n","“Alcohol”, que nada tiene que ver con Deep Learning:"],"metadata":{"id":"oB9HHMIxRlvE"}},{"cell_type":"code","source":["print(generate_text(model, start_string=\"Alcohol \"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDb0jxHZRmlG","executionInfo":{"status":"ok","timestamp":1646386935962,"user_tz":-60,"elapsed":5145,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"066e7e1f-cdb7-40c5-aa0b-8fd511526f1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alcohol en Keras se considera como una secuencia de capas que cada una de ellas. Si el lector al acabar el libro completo tenga una vision general del metodo fit() en la segunda parte del libro hablaremos mas sobre las diversas redes capitulos para los convolucionales para reducir los tamanos son raramente utilizados e probabilidad sobre clases de salida de tamanos obtener de mas detalle con siguientes de activacion ReLU. En este caso, estamos hablando de casi 100 millones de predicciones por segundo qu\n"]}]},{"cell_type":"markdown","source":["Probemos ahora con una palabra como \"modelo\" o “activación” a ver que\n","pasa:"],"metadata":{"id":"gybQMmNCTsMa"}},{"cell_type":"code","source":["print(generate_text(model, start_string=\"modelo \"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMG0w31kTs-F","executionInfo":{"status":"ok","timestamp":1646386951456,"user_tz":-60,"elapsed":4605,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"d8c3c6a5-028d-477b-e7c0-0ed129adcc71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["modelo de programacion, sin adornos y maximizando la legra san capas ocultas (agroyan en los casos anteriores, el codigo se puede requerir mas capacidad de computacion que antes solo estaba disponible para grandes organizaciones o gobiernos.\r\n","Acempara con el metodo summary() que indica que se anada con este ejemplo usaremos una conocida como funcion sigmoid102 que retorna el imagina el numero de personas que trabajan ya en Deep Learning y empresas que invierte que es una aproximacion que funciona muy b\n"]}]},{"cell_type":"code","source":["print(generate_text(model, start_string=\"activacion\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646387033955,"user_tz":-60,"elapsed":4602,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"0d6851ae-829d-41d1-aa0b-5c5b7965fcac","id":"3Av6EnamT9Xj"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["activacion, ahora ya no son encontramos con redes neuronales. La ventaja de tanh es que esta indicando que el modelo que hemos creado en el caso de las redes neuronales, pensemos en conciso por informacion contenida en el conjunto de entrenamiento no es suficiente para entrenar a todas las neuronas de este primer argumento para aquellas esta concepto de peso W de la misma dimension que la entrada  y para ello softmax usa el valor de la funcion de activacion de la primera capa, pasando de una sigmoid a una\n"]}]},{"cell_type":"markdown","source":["En resumen, el modelo presentado parece que ha aprendido a generar texto\n","de manera interesante, teniendo en cuenta el reducido dataset inicial con el\n","que se ha entrenado. Como ya hemos avanzado, proponemos que el lector\n","pruebe con otros conjuntos de datos de tipo texto. Por ejemplo en el artículo\n","“The Unreasonable Effectiveness of Recurrent Neural Network” del blog de Andrey\n","Karpathy91 el lector puede encontrar varios ejemplos de datos de tipo texto\n","que el lector puede usar directamente simplemente cambiando la URL del\n","fichero de texto de entrada al código propuesto en este capítulo"],"metadata":{"id":"nxE-iEctUTYe"}},{"cell_type":"markdown","source":["# Probando otro ejemplo"],"metadata":{"id":"yjfYzfubWjjK"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# DESCARGAMOS EL MODELO DE ENTRENAMIENTO\n","path_to_fileDL = tf.keras.utils.get_file('Shakespear.txt',\n","'https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt')\n","\n","text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n","vocab = sorted(set(text))\n","print('Longitud del texto: {} carácteres'.format(len(text)))\n","print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n","\n","#Creamos el conversor numero character index y viceversa\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","# Ahora tenemos un representacion de un caracter para cada numero\n","text_as_int = np.array([char2idx[c] for c in text])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwHu5GGvWl1X","executionInfo":{"status":"ok","timestamp":1646388736814,"user_tz":-60,"elapsed":456,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"outputId":"29770eeb-4797-43a2-9023-8c0f040fbd3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Longitud del texto: 99993 carácteres\n","El texto está compuesto de estos 62 carácteres:\n"]}]},{"cell_type":"code","source":["# PREPARACION DE DATOS DE ENTREDA\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","seq_length = 100\n","sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"],"metadata":{"id":"iDiLZe7tYHUD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CONJUNTO DE DATOS ENTRADA/SALIDA\n","def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text = chunk[1:]\n","  return input_text, target_text\n","  \n","dataset = sequences.map(split_input_target)"],"metadata":{"id":"SE2N2abCYTIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CREACION DE BATCHES\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"c9x3zOd4Yzbm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DEFINICION DEL MODELO\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = Sequential()\n","  model.add(Embedding(input_dim=vocab_size, \n","                      output_dim=embedding_dim, \n","                      batch_input_shape=[batch_size, None]))\n","  model.add(LSTM(rnn_units,\n","                 return_sequences=True,\n","                 stateful=True,\n","                 recurrent_initializer='glorot_uniform'))\n","  model.add(Dense(vocab_size))\n","  return model\n","\n","\n","\n","vocab_size = len(vocab)\n","embedding_dim = 256\n","rnn_units = 1024\n","\n","model = build_model(\n","  vocab_size = vocab_size,\n","  embedding_dim=embedding_dim,\n","  rnn_units=rnn_units,\n","  batch_size=BATCH_SIZE)"],"metadata":{"id":"Q7a2PeAcZEVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MOSTRAMOS LA INFORMACION DEL MODELO\n","model.summary()\n","\n","print('----------------------------------------------------------------')\n","for input_example_batch, target_example_batch in dataset.take(1):\n","  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n","  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")\n","\n","print('----------------------------------------------------------------')\n","for input_example_batch, target_example_batch in dataset.take(1):  \n","  example_batch_predictions = model(input_example_batch)\n","  print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"],"metadata":{"executionInfo":{"status":"ok","timestamp":1646388752644,"user_tz":-60,"elapsed":979,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"LMdNgTpOZEVL","outputId":"60c6f3fb-e22a-4e8f-d270-9b573438d744"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (64, None, 256)           15872     \n","                                                                 \n"," lstm_2 (LSTM)               (64, None, 1024)          5246976   \n","                                                                 \n"," dense_2 (Dense)             (64, None, 62)            63550     \n","                                                                 \n","=================================================================\n","Total params: 5,326,398\n","Trainable params: 5,326,398\n","Non-trainable params: 0\n","_________________________________________________________________\n","----------------------------------------------------------------\n","Input: (64, 100) # (batch_size, sequence_length)\n","Target: (64, 100) # (batch_size, sequence_length)\n","----------------------------------------------------------------\n","Prediction:  (64, 100, 62) # (batch_size, sequence_length, vocab_size)\n"]}]},{"cell_type":"code","source":["# DEFINICION DE LOSS\n","def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits,\n","                                                        from_logits=True)"],"metadata":{"id":"KLZyblAiZ2yb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# COMPILAR EL MODELO\n","model.compile(optimizer='adam', loss=loss)"],"metadata":{"id":"dTalTWiRZ5WO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ESPECIFICAR CHECKPOINT\n","import os\n","\n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"],"metadata":{"id":"XojdDUOPZ5WQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ENTRENAMIENTO DEL MODELO\n","EPOCHS=50\n","history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1646389006408,"user_tz":-60,"elapsed":207313,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"eLeDEVSSaFeB","outputId":"0e13b4d6-c8cd-4217-e016-9a677285c24a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","15/15 [==============================] - 5s 185ms/step - loss: 3.5722\n","Epoch 2/50\n","15/15 [==============================] - 3s 179ms/step - loss: 3.2211\n","Epoch 3/50\n","15/15 [==============================] - 3s 190ms/step - loss: 3.1131\n","Epoch 4/50\n","15/15 [==============================] - 3s 180ms/step - loss: 2.8447\n","Epoch 5/50\n","15/15 [==============================] - 3s 178ms/step - loss: 2.5670\n","Epoch 6/50\n","15/15 [==============================] - 3s 185ms/step - loss: 2.4330\n","Epoch 7/50\n","15/15 [==============================] - 3s 180ms/step - loss: 2.3493\n","Epoch 8/50\n","15/15 [==============================] - 3s 175ms/step - loss: 2.2849\n","Epoch 9/50\n","15/15 [==============================] - 3s 185ms/step - loss: 2.2304\n","Epoch 10/50\n","15/15 [==============================] - 3s 179ms/step - loss: 2.1761\n","Epoch 11/50\n","15/15 [==============================] - 3s 181ms/step - loss: 2.1288\n","Epoch 12/50\n","15/15 [==============================] - 3s 180ms/step - loss: 2.0756\n","Epoch 13/50\n","15/15 [==============================] - 3s 178ms/step - loss: 2.0298\n","Epoch 14/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.9897\n","Epoch 15/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.9423\n","Epoch 16/50\n","15/15 [==============================] - 3s 179ms/step - loss: 1.9042\n","Epoch 17/50\n","15/15 [==============================] - 3s 179ms/step - loss: 1.8658\n","Epoch 18/50\n","15/15 [==============================] - 3s 186ms/step - loss: 1.8241\n","Epoch 19/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.7856\n","Epoch 20/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.7489\n","Epoch 21/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.7108\n","Epoch 22/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.6694\n","Epoch 23/50\n","15/15 [==============================] - 3s 181ms/step - loss: 1.6361\n","Epoch 24/50\n","15/15 [==============================] - 3s 179ms/step - loss: 1.5941\n","Epoch 25/50\n","15/15 [==============================] - 3s 192ms/step - loss: 1.5560\n","Epoch 26/50\n","15/15 [==============================] - 3s 179ms/step - loss: 1.5141\n","Epoch 27/50\n","15/15 [==============================] - 3s 178ms/step - loss: 1.4765\n","Epoch 28/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.4281\n","Epoch 29/50\n","15/15 [==============================] - 3s 180ms/step - loss: 1.3808\n","Epoch 30/50\n","15/15 [==============================] - 3s 186ms/step - loss: 1.3349\n","Epoch 31/50\n","15/15 [==============================] - 3s 179ms/step - loss: 1.2836\n","Epoch 32/50\n","15/15 [==============================] - 3s 188ms/step - loss: 1.2282\n","Epoch 33/50\n","15/15 [==============================] - 3s 181ms/step - loss: 1.1747\n","Epoch 34/50\n","15/15 [==============================] - 3s 183ms/step - loss: 1.1155\n","Epoch 35/50\n","15/15 [==============================] - 3s 181ms/step - loss: 1.0568\n","Epoch 36/50\n","15/15 [==============================] - 3s 179ms/step - loss: 0.9945\n","Epoch 37/50\n","15/15 [==============================] - 3s 190ms/step - loss: 0.9308\n","Epoch 38/50\n","15/15 [==============================] - 3s 180ms/step - loss: 0.8645\n","Epoch 39/50\n","15/15 [==============================] - 3s 180ms/step - loss: 0.8064\n","Epoch 40/50\n","15/15 [==============================] - 3s 185ms/step - loss: 0.7458\n","Epoch 41/50\n","15/15 [==============================] - 3s 190ms/step - loss: 0.6896\n","Epoch 42/50\n","15/15 [==============================] - 3s 180ms/step - loss: 0.6312\n","Epoch 43/50\n","15/15 [==============================] - 3s 194ms/step - loss: 0.5809\n","Epoch 44/50\n","15/15 [==============================] - 3s 180ms/step - loss: 0.5406\n","Epoch 45/50\n","15/15 [==============================] - 3s 179ms/step - loss: 0.4991\n","Epoch 46/50\n","15/15 [==============================] - 3s 179ms/step - loss: 0.4631\n","Epoch 47/50\n","15/15 [==============================] - 3s 190ms/step - loss: 0.4325\n","Epoch 48/50\n","15/15 [==============================] - 3s 179ms/step - loss: 0.4047\n","Epoch 49/50\n","15/15 [==============================] - 3s 179ms/step - loss: 0.3811\n","Epoch 50/50\n","15/15 [==============================] - 3s 178ms/step - loss: 0.3627\n"]}]},{"cell_type":"code","source":["# CARGA DEL MODELO\n","model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","model.build(tf.TensorShape([1, None]))"],"metadata":{"id":"YRfZz7RsaUQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FUNCION GENERADORA DE TEXTO\n","def generate_text(model, start_string):\n","  num_generate = 500\n","  input_eval = [char2idx[s] for s in start_string]\n","\n","  input_eval = tf.expand_dims(input_eval, 0)\n","  text_generated = []\n","\n","  temperature = 0.5\n","\n","  model.reset_states()\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","\n","    predictions = tf.squeeze(predictions, 0)\n","    predictions = predictions / temperature\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","    input_eval = tf.expand_dims([predicted_id], 0)\n","\n","    text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"],"metadata":{"id":"u7KoViFsaVrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GENERACION DE TEXTO\n","print(generate_text(model, start_string=\"I \"))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1646389529045,"user_tz":-60,"elapsed":4302,"user":{"displayName":"boxlover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxbFoJYuz2Bmpyi0T1U6CUHWcs29YVsU1uHK0UYw=s64","userId":"03008156017960112380"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"fz9byXvgaVrS","outputId":"13f888bb-6af9-4125-a849-de70f14b7d95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I should devery prace\n","As I did wear ere and give thee full of this exematake them for a king,\n","And now thee but seams and some I would not beng to contemply,\n","I think what thou hast not make her presss'd out of this to be of it,\n","I seak him bas with your awn backind the bloody offickings; and be it a lately and this beard not celsen about man;\n","And so she shall prieve your onf lords, a crotest be so,\n","And that I have make him coming; and we shall be faliand did in the sight of dongors lecking\n","The lows \n"]}]}]}